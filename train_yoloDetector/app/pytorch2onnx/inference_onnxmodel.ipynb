{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assisted-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "classes = [\"b4_bracket\", \"blue_cable_tie\",\"bolt_v1\",\"bolt_v3\",\"bolt_v4\",\"bolt_v5\",\"green_disk\",\"screw_v1\",\"screw_v2\",\"transparent_cap\",\"welding_seam\",\"welding_spot\",\"yellow_cable_tie\",\"yellow_cap\"]\n",
    "model_path = \"/home/tandonsa/PycharmProjects/FCM-model_dev/yolov5/runs/train/exp/weights/best.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greek-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "320\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(model_path)\n",
    "IN_IMAGE_H = session.get_inputs()[0].shape[2]\n",
    "IN_IMAGE_W = session.get_inputs()[0].shape[3]\n",
    "batch_size = session.get_inputs()[0].shape[0]\n",
    "print(batch_size)\n",
    "print(IN_IMAGE_H)\n",
    "print(IN_IMAGE_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considered-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(img_src,img_shape,model):\n",
    "    img_in = cv2.resize(img_src, img_shape, interpolation=cv2.INTER_LINEAR)\n",
    "    img_in = np.transpose(img_in, (2, 0, 1)).astype(np.float32)\n",
    "    img_in = np.expand_dims(img_in, axis=0)\n",
    "    img_in /= 255.0\n",
    "    # Compute\n",
    "    input_name = model.get_inputs()[0].name\n",
    "    outputs = model.run(None, {input_name: img_in})\n",
    "    \n",
    "    detection_classes,detection_boxes,detection_scores, num_detections = outputs\n",
    "    print(\"input image\",img_in.shape)\n",
    "    print(\"detection_boxes\",detection_boxes.shape)\n",
    "    print(\"detection_classes\",detection_classes.shape)\n",
    "    print(\"detection_scores\",detection_scores.shape)\n",
    "    print(\"num_detections\",num_detections.shape)\n",
    "#     boxes = post_processing(img_in,outputs ,0.4, 0.6)\n",
    "#     print(boxes)\n",
    "    return img_in,detection_classes,detection_boxes,detection_scores, num_detections\n",
    "#     return boxes\n",
    "\n",
    "\n",
    "def nms_cpu(boxes, confs, nms_thresh=0.5, min_mode=False):\n",
    "    # print(boxes.shape)\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = confs.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        idx_self = order[0]\n",
    "        idx_other = order[1:]\n",
    "\n",
    "        keep.append(idx_self)\n",
    "\n",
    "        xx1 = np.maximum(x1[idx_self], x1[idx_other])\n",
    "        yy1 = np.maximum(y1[idx_self], y1[idx_other])\n",
    "        xx2 = np.minimum(x2[idx_self], x2[idx_other])\n",
    "        yy2 = np.minimum(y2[idx_self], y2[idx_other])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        inter = w * h\n",
    "\n",
    "        if min_mode:\n",
    "            over = inter / np.minimum(areas[order[0]], areas[order[1:]])\n",
    "        else:\n",
    "            over = inter / (areas[order[0]] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(over <= nms_thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "    \n",
    "    return np.array(keep)\n",
    "            \n",
    "\n",
    "def post_processing(img,output,conf_thresh, nms_thresh):\n",
    "    box_array = output[1]  # (1, 3, 40, 40, 19) # [batch, num, 1, 4]\n",
    "    print(\"BOX array shape\",box_array.shape)\n",
    "    confs = output[0] # (1, 6300, 19)   # [batch, num, num_classes]\n",
    "    print(\"Confidence shape \",confs.shape) \n",
    "    t1 = time.time()\n",
    "    \n",
    "    if type(box_array).__name__ != 'ndarray':\n",
    "        box_array = box_array.cpu().detach().numpy()\n",
    "        confs = confs.cpu().detach().numpy()\n",
    "    \n",
    "    num_classes = confs.shape[2]\n",
    "    print(\"total num classes\",num_classes)\n",
    "    \n",
    "    max_conf = np.max(confs, axis=2)\n",
    "    max_id = np.argmax(confs, axis=2)\n",
    "    t2 = time.time()\n",
    "    \n",
    "    bboxes_batch = []\n",
    "    for i in range(box_array.shape[0]):\n",
    "        argwhere = max_conf[i] > conf_thresh\n",
    "        l_box_array = box_array[i, argwhere, :]\n",
    "        l_max_conf = max_conf[i, argwhere]\n",
    "        l_max_id = max_id[i, argwhere]\n",
    "        bboxes = []\n",
    "        # nms for each class\n",
    "        for j in range(num_classes):\n",
    "            cls_argwhere = l_max_id == j\n",
    "            ll_box_array = l_box_array[cls_argwhere, :]\n",
    "            ll_max_conf = l_max_conf[cls_argwhere]\n",
    "            ll_max_id = l_max_id[cls_argwhere]\n",
    "\n",
    "            keep = nms_cpu(ll_box_array, ll_max_conf, nms_thresh)\n",
    "            \n",
    "            if (keep.size > 0):\n",
    "                ll_box_array = ll_box_array[keep, :]\n",
    "                ll_max_conf = ll_max_conf[keep]\n",
    "                ll_max_id = ll_max_id[keep]\n",
    "\n",
    "                for k in range(ll_box_array.shape[0]):\n",
    "                    bboxes.append([ll_box_array[k, 0], ll_box_array[k, 1], ll_box_array[k, 2], ll_box_array[k, 3], ll_max_conf[k], ll_max_conf[k], ll_max_id[k]])\n",
    "        \n",
    "        bboxes_batch.append(bboxes)\n",
    "        \n",
    "    t3 = time.time()\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    print('       max and argmax : %f' % (t2 - t1))\n",
    "    print('                  nms : %f' % (t3 - t2))\n",
    "    print('Post processing total : %f' % (t3 - t1))\n",
    "    print('-----------------------------------')\n",
    "    \n",
    "    return bboxes_batch\n",
    "\n",
    "def class_colors(names):\n",
    "\n",
    "    return {name: (\n",
    "        np.random.randint(0, 255),\n",
    "        np.random.randint(0, 255),\n",
    "        np.random.randint(0, 255)) for name in names}\n",
    "\n",
    "def plot_boxes_cv2(img, boxes, savename=None, class_names=None, color=None,save_cords=None):\n",
    "    img = np.copy(img)\n",
    "    color = class_colors(class_names)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    \n",
    "    for i in range(len(boxes[0])):\n",
    "        box = boxes[0]\n",
    "        x1 = int(box[i][0] * width)\n",
    "        y1 = int(box[i][1] * height)\n",
    "        x2 = int(box[i][2] * width)\n",
    "        y2 = int(box[i][3] * height)\n",
    "        if class_names:\n",
    "            cls_conf = box[i][5]\n",
    "            cls_id = box[i][6]\n",
    "            cls_label = class_names[cls_id]\n",
    "            img = cv2.putText(img, class_names[cls_id], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX,2, color[cls_label], 2)\n",
    "        img = cv2.rectangle(img, (x1, y1), (x2, y2),color[cls_label], 5)\n",
    "        if save_cords:\n",
    "            fd = open(save_cords,'a+')\n",
    "            fd.write(\"{} {} {} {} {}\\n\".format(class_names[cls_id],x1,y1,x2,y2))\n",
    "        \n",
    "    if savename:\n",
    "        print(\"save plot results to %s\" % savename)\n",
    "        cv2.imwrite(savename, img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabulous-natural",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image (1, 3, 320, 320)\n",
      "detection_boxes (1, 3, 40, 40, 19)\n",
      "detection_classes (1, 6300, 19)\n",
      "detection_scores (1, 3, 20, 20, 19)\n",
      "num_detections (1, 3, 10, 10, 19)\n"
     ]
    }
   ],
   "source": [
    "testimg_file = '/home/tandonsa/PycharmProjects/FCM-model_dev/yolov5_azureml/src/resources/val/images/NLRRM05J_223283605J200312113415_20200312-121039_front_camera_0_system1.jpg'\n",
    "test_img = cv2.imread(testimg_file)\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "test_img,det_classes,det_boxes,det_scores, num_det =detect(test_img,img_shape=(IN_IMAGE_H,IN_IMAGE_W),model=session)\n",
    "\n",
    "# classes = [\"b4_bracket\", \"blue_cable_tie\",\"bolt_v1\",\"bolt_v3\",\"bolt_v4\",\"bolt_v5\",\"green_disk\",\"screw_v1\",\"screw_v2\",\"transparent_cap\",\"welding_seam\",\"welding_spot\",\"yellow_cable_tie\",\"yellow_cap\"]\n",
    "# img = plot_boxes_cv2(test_img,boxes,class_names=classes,savename='predicted.jpg',save_cords='boxes.txt')\n",
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = num_det.shape[0]\n",
    "for batch in range(0, batch_size):\n",
    "    c = det_classes[batch][1]\n",
    "    d = det_boxes[batch][1]\n",
    "    print(c.shape,d.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw results\n",
    "def draw_detection(draw, d, c):\n",
    "    width, height = draw.im.size\n",
    "    # the box is relative to the image size so we multiply with height and width to get pixels.\n",
    "    top = d[0] * height\n",
    "    left = d[1] * width\n",
    "    bottom = d[2] * height\n",
    "    right = d[3] * width\n",
    "    top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "    left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "    bottom = min(height, np.floor(bottom + 0.5).astype('int32'))\n",
    "    right = min(width, np.floor(right + 0.5).astype('int32'))\n",
    "    label = coco_classes[c.astype('int32') - 1] # shift to zero element\n",
    "    label_size = draw.textsize(label)\n",
    "    text_origin = tuple(np.array([left + 1, top + 1]))\n",
    "    color = ImageColor.getrgb(\"yellow\")\n",
    "    thickness = 0\n",
    "    draw.rectangle([left + thickness, top + thickness, right - thickness, bottom - thickness], outline=color)\n",
    "    draw.text(text_origin, label, fill=color, font=font)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-tractor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
